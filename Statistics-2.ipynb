{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a865de43",
   "metadata": {},
   "source": [
    "#Q1\n",
    "The three measures of central tendency are:\n",
    "\n",
    "1. Mean: The mean, often referred to as the average, is calculated by summing up all the values in a dataset and then dividing by the total number of values. It provides a measure of the \"typical\" value in a dataset.\n",
    "\n",
    "2. Median: The median is the middle value in a dataset when it is arranged in ascending or descending order. If there is an even number of values, the median is the average of the two middle values. The median is less affected by extreme outliers than the mean and is a measure of the central value.\n",
    "\n",
    "3. Mode: The mode is the value that appears most frequently in a dataset. A dataset can have one mode (unimodal), more than one mode (multimodal), or no mode if all values occur with the same frequency. The mode is useful for identifying the most frequently occurring category or value in a dataset.\n",
    "\n",
    "These measures help to summarize and describe the central or typical values within a set of data, providing insights into the data's distribution and characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad8d76",
   "metadata": {},
   "source": [
    "#Q2\n",
    "The mean, median, and mode are three different measures of central tendency used to describe the typical or central values within a dataset. They provide different insights into the distribution of data and are used in various contexts depending on the characteristics of the data and the specific goals of analysis. Here's how they differ and how they are used:\n",
    "\n",
    "1. Mean:\n",
    "   - Calculation: The mean, often called the average, is calculated by adding up all the values in the dataset and then dividing by the total number of values. The formula is: Mean = (Sum of all values) / (Number of values).\n",
    "   - Use: The mean represents the arithmetic average of the data and provides a measure of the \"center\" of the dataset. It is useful for understanding the overall balance of values and is widely used in various statistical analyses. However, it can be sensitive to extreme outliers, which can significantly affect its value.\n",
    "\n",
    "2. Median:\n",
    "   - Calculation: The median is the middle value in a dataset when the values are sorted in ascending or descending order. If there's an even number of values, the median is the average of the two middle values.\n",
    "   - Use: The median is less affected by extreme outliers compared to the mean. It provides a measure of the central value that is more robust in the presence of skewed or non-normally distributed data. It's especially useful when you want to understand the typical value without being influenced by extreme values.\n",
    "\n",
    "3. Mode:\n",
    "   - Calculation: The mode is the value that occurs most frequently in a dataset.\n",
    "   - Use: The mode is used to identify the most frequently occurring value or category in a dataset. It's particularly helpful in categorical data analysis but can also be used with numerical data. In cases where data is multimodal (having more than one mode), it helps identify multiple central values.\n",
    "\n",
    "In summary, the choice of which measure of central tendency to use depends on the nature of your data and your analysis objectives:\n",
    "\n",
    "- Use the mean when you want a balanced measure of central tendency and your data is approximately normally distributed without significant outliers.\n",
    "- Use the median when your data is skewed, contains outliers, or when you want a measure less influenced by extreme values.\n",
    "- Use the mode when you want to identify the most frequently occurring value or category, especially in categorical data, or when looking for multiple central values (multimodal data).\n",
    "\n",
    "In practice, it's often a good idea to consider all three measures together to get a more complete understanding of the central tendency of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f6485bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "s=[178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b44268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.01875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58e15d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7cd7054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.mode(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00839d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7885814036548633"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4\n",
    "t=[178,177,176,177,178.2,178,175,179,180,175,178.9,176.2,177,172.5,178,176.5]\n",
    "np.std(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e891558",
   "metadata": {},
   "source": [
    "#Q5\n",
    "Measures of dispersion, such as range, variance, and standard deviation, are used to describe the spread or variability within a dataset. They provide valuable information about how data points are distributed around the central tendency (mean, median, or mode) and can help assess the degree of variability or consistency in a dataset. Here's how these measures are used, along with an example:\n",
    "\n",
    "1. Range:\n",
    "   - The range is the simplest measure of dispersion. It quantifies the spread of data by calculating the difference between the maximum and minimum values in the dataset.\n",
    "   - Range = Maximum Value - Minimum Value\n",
    "   - A larger range indicates greater variability, while a smaller range suggests less variability.\n",
    "   - Example: Consider a dataset of daily temperatures (in degrees Fahrenheit) for a week: [68, 72, 74, 66, 80, 62, 76]. The range would be 80 - 62 = 18 degrees Fahrenheit, indicating a fairly wide temperature variation during the week.\n",
    "\n",
    "2. Variance:\n",
    "   - Variance measures how each data point in the dataset deviates from the mean. It calculates the average of the squared differences between each data point and the mean.\n",
    "   - Variance = Σ(x - μ)² / (n - 1), where x is each data point, μ is the mean, and n is the number of data points.\n",
    "   - A higher variance indicates greater dispersion, while a lower variance suggests less dispersion.\n",
    "   - Example: Let's take a dataset of exam scores for a class: [85, 90, 88, 78, 92]. The mean is 86.6. Calculating the variance gives us approximately 19.3, indicating moderate variability in the exam scores.\n",
    "\n",
    "3. Standard Deviation:\n",
    "   - The standard deviation is closely related to the variance and measures the average deviation of data points from the mean. It is the square root of the variance.\n",
    "   - Standard Deviation = √Variance\n",
    "   - It provides a measure of spread in the same units as the original data, making it easier to interpret.\n",
    "   - A higher standard deviation implies greater variability, while a lower standard deviation implies less variability.\n",
    "   - Example: Using the same exam scores dataset, if the variance is approximately 19.3, the standard deviation would be approximately 4.4. This standard deviation value represents the average deviation of scores from the mean and is in the same units as the scores themselves.\n",
    "\n",
    "In summary, measures of dispersion help you understand how data points are distributed around the central tendency and provide insights into the variability or spread of the data. The range gives you a simple range of values, while variance and standard deviation provide more detailed information about the extent of deviation from the mean. These measures are essential for assessing the consistency, reliability, and overall characteristics of a dataset in various fields, including statistics, finance, and science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6268892b",
   "metadata": {},
   "source": [
    "#Q6\n",
    "A Venn diagram is a visual representation used to depict the relationships and commonalities between different sets or groups. It consists of overlapping circles or other closed shapes, each representing a set or category, with the overlapping regions indicating the elements that belong to multiple sets. Venn diagrams are named after John Venn, a British mathematician and logician who introduced this method of visual representation in the late 19th century.\n",
    "\n",
    "Key characteristics of a Venn diagram include:\n",
    "\n",
    "1. Sets: Each circle or closed shape in a Venn diagram represents a specific set or category. The elements or members of a set are usually listed within or near the circle.\n",
    "\n",
    "2. Overlapping Regions: Overlapping regions in the diagram represent elements that belong to multiple sets. The size of the overlapping area indicates the extent of commonality between the sets.\n",
    "\n",
    "3. Non-overlapping Regions: The non-overlapping parts of the circles represent elements that are unique to each set and do not belong to any other set.\n",
    "\n",
    "Venn diagrams are widely used in various fields, including mathematics, logic, statistics, and data analysis, to visually illustrate concepts related to set theory, logical relationships, and data comparisons. They are particularly useful for showing the intersection and differences between sets, making complex relationships easier to understand at a glance.\n",
    "\n",
    "Common types of Venn diagrams include:\n",
    "\n",
    "1. Two-set Venn diagrams: These diagrams use two circles to represent two sets and their overlap.\n",
    "\n",
    "2. Three-set Venn diagrams: These diagrams use three circles to represent three sets and their overlapping relationships.\n",
    "\n",
    "3. Multi-set Venn diagrams: These diagrams can represent more than three sets, with additional circles and overlapping regions.\n",
    "\n",
    "Venn diagrams are a valuable tool for problem-solving, decision-making, and data visualization when dealing with sets or groups of items, such as in the fields of mathematics, statistics, biology, and information science. They are also frequently used in educational settings to teach set theory and logical concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adadd11",
   "metadata": {},
   "source": [
    "#Q7\n",
    "\n",
    "A = (2,3,4,5,6,7)\n",
    "\n",
    "B = (0,2,6,8,10)\n",
    "\n",
    "AnB=(2,6)\n",
    "\n",
    "AUB=(0,2,3,4,5,6,7,8,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b612e69",
   "metadata": {},
   "source": [
    "#Q8\n",
    "\n",
    "Skewness in data is a measure of the asymmetry or lack of symmetry in the distribution of data points within a dataset. It quantifies the degree to which the data is skewed or biased toward one end of the distribution, either to the left (negatively skewed) or to the right (positively skewed), relative to the central tendency (mean, median, or mode). Understanding skewness is essential in statistics and data analysis because it provides insights into the shape and characteristics of a dataset's distribution.\n",
    "\n",
    "There are three common types of skewness:\n",
    "\n",
    "1. Negative Skewness (Left Skew):\n",
    "   - In a negatively skewed distribution, the tail of the data distribution extends more to the left, and the majority of data points are concentrated on the right side of the distribution.\n",
    "   - The mean is typically less than the median in a negatively skewed distribution.\n",
    "   - Negative skewness often indicates that the data is skewed toward higher values, with a long tail of lower values.\n",
    "   - Example: Income distribution in a country, where most people earn moderate incomes, but there are a few extremely wealthy individuals.\n",
    "\n",
    "2. Positive Skewness (Right Skew):\n",
    "   - In a positively skewed distribution, the tail of the data distribution extends more to the right, and the majority of data points are concentrated on the left side of the distribution.\n",
    "   - The mean is typically greater than the median in a positively skewed distribution.\n",
    "   - Positive skewness often indicates that the data is skewed toward lower values, with a long tail of higher values.\n",
    "   - Example: The distribution of daily stock returns, where most days have small positive returns, but there are occasional days with very high positive returns.\n",
    "\n",
    "3. Symmetrical or No Skewness:\n",
    "   - In a perfectly symmetrical distribution, there is no skewness, and the data is evenly distributed around the central measure (mean, median, or mode).\n",
    "   - The mean, median, and mode are all equal in a symmetrical distribution.\n",
    "   - Example: A normal distribution, which is symmetric with a bell-shaped curve.\n",
    "\n",
    "Measuring skewness is typically done using statistical formulas or software tools. Common measures of skewness include the skewness coefficient (or skewness index), which quantifies the degree and direction of skewness, and graphical representations like histograms and box plots, which visually display the skewness of the data.\n",
    "\n",
    "Understanding skewness is important in various fields, such as finance, economics, and biology, as it can influence decision-making and the selection of appropriate statistical methods for data analysis. Skewness helps analysts and researchers identify patterns, assess the distribution of data, and make informed inferences about the underlying processes or phenomena being studied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cb04cc",
   "metadata": {},
   "source": [
    "#Q9\n",
    "\n",
    "If a dataset is right-skewed, the position of the median with respect to the mean will typically be as follows:\n",
    "\n",
    "1. The Mean (Average) will be Greater than the Median:\n",
    "   - In a right-skewed distribution, the tail of the distribution extends to the right, which means there are some extreme values or outliers on the right side of the distribution.\n",
    "   - The mean is influenced by these extreme values because it takes into account all data points. Therefore, the presence of larger values on the right side of the distribution will pull the mean to the right.\n",
    "   - Consequently, the mean will be greater than the median.\n",
    "\n",
    "To summarize, in a right-skewed distribution, the mean is generally larger than the median. This relationship between the mean and median reflects the asymmetry of the distribution, with the mean being influenced by the skewness introduced by the right tail of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd448d5f",
   "metadata": {},
   "source": [
    "#Q10\n",
    "\n",
    "Covariance and correlation are both measures used in statistics to quantify the relationship between two variables, but they serve slightly different purposes and have distinct properties:\n",
    "\n",
    "1. Covariance:\n",
    "   - Covariance measures the degree to which two variables change together. It indicates whether an increase in one variable corresponds to an increase or decrease in another variable.\n",
    "   - The formula for the sample covariance between two variables X and Y is:\n",
    "     Cov(X, Y) = Σ [(X_i - X̄) * (Y_i - Ȳ)] / (n - 1), where X_i and Y_i are individual data points, X̄ and Ȳ are the sample means of X and Y, and n is the number of data points.\n",
    "   - Covariance can be positive, negative, or zero:\n",
    "     - Positive covariance indicates that as one variable increases, the other tends to increase as well.\n",
    "     - Negative covariance indicates that as one variable increases, the other tends to decrease.\n",
    "     - Zero covariance indicates no linear relationship between the variables.\n",
    "   - However, the magnitude of covariance is not standardized and can be difficult to interpret because it depends on the units of the variables. Therefore, it's not a good measure for comparing the strength of relationships between different pairs of variables.\n",
    "\n",
    "2. Correlation:\n",
    "   - Correlation is a standardized measure that quantifies the strength and direction of the linear relationship between two variables. It provides a more interpretable and consistent measure of association than covariance.\n",
    "   - The most commonly used correlation coefficient is the Pearson correlation coefficient (often denoted as \"r\"), which ranges from -1 to 1:\n",
    "     - r = 1 indicates a perfect positive linear relationship.\n",
    "     - r = -1 indicates a perfect negative linear relationship.\n",
    "     - r = 0 indicates no linear relationship.\n",
    "   - The formula for the Pearson correlation coefficient is:\n",
    "     r = Σ [(X_i - X̄) * (Y_i - Ȳ)] / [√Σ(X_i - X̄)² * Σ(Y_i - Ȳ)²]\n",
    "   - Unlike covariance, correlation is unitless and always falls within the range of -1 to 1, making it easier to compare and interpret the strength and direction of relationships between variables.\n",
    "   - Correlation also helps identify both positive and negative linear relationships, as well as the strength of those relationships.\n",
    "\n",
    "In statistical analysis:\n",
    "\n",
    "- Covariance is often used to assess the relationship between two variables, but it is more suitable for understanding the direction of the relationship rather than its strength. It is not a standardized measure.\n",
    "\n",
    "- Correlation, especially the Pearson correlation coefficient, is widely used to quantify the strength and direction of linear relationships between two variables. It is a standardized measure that facilitates comparison across different pairs of variables.\n",
    "\n",
    "Correlation is particularly useful in various fields, including finance, economics, social sciences, and data analysis, for understanding and modeling relationships between variables, identifying patterns, and making predictions. It provides valuable insights into how changes in one variable relate to changes in another variable, allowing for more robust statistical analysis and decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6654a4",
   "metadata": {},
   "source": [
    "#Q11\n",
    "\n",
    "The formula for calculating the sample mean (also known as the sample average) of a dataset is as follows:\n",
    "\n",
    "Sample Mean (x̄) = (Sum of all data points) / (Number of data points)\n",
    "\n",
    "To calculate the sample mean, you sum up all the values in the dataset and then divide by the total number of data points.\n",
    "\n",
    "Here's an example calculation for a dataset:\n",
    "\n",
    "Let's say you have the following dataset of exam scores for a class:\n",
    "\n",
    "80, 85, 92, 88, 76, 90, 78, 85, 86, 89\n",
    "\n",
    "To find the sample mean (x̄):\n",
    "\n",
    "Step 1: Sum up all the values in the dataset:\n",
    "80 + 85 + 92 + 88 + 76 + 90 + 78 + 85 + 86 + 89 = 869\n",
    "\n",
    "Step 2: Count the number of data points (which is 10 in this case).\n",
    "\n",
    "Step 3: Calculate the sample mean by dividing the sum by the number of data points:\n",
    "x̄ = 869 / 10 = 86.9\n",
    "\n",
    "So, the sample mean of the dataset is 86.9. This means that, on average, the students in the class scored approximately 86.9 on the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6604ef2a",
   "metadata": {},
   "source": [
    "#Q12\n",
    "\n",
    "In a normal distribution, also known as a Gaussian distribution or bell curve, there is a specific relationship between its measures of central tendency—mean, median, and mode. This relationship is a key characteristic of the normal distribution:\n",
    "\n",
    "1. Mean (μ): In a normal distribution, the mean is located at the center of the distribution. It is the point of highest symmetry and is equal to the median and mode. Therefore, in a normal distribution, μ = Median = Mode.\n",
    "\n",
    "2. Median: The median of a normal distribution is also located at the center of the distribution, and it is equal to the mean and mode. So, in a normal distribution, Median = μ = Mode.\n",
    "\n",
    "3. Mode: The mode of a normal distribution is also found at the peak of the distribution, and it is equal to both the mean and median. In a normal distribution, Mode = μ = Median.\n",
    "\n",
    "This equality among the mean, median, and mode in a normal distribution is a fundamental property of symmetric, unimodal distributions like the normal distribution. The symmetrical bell-shaped curve of the normal distribution ensures that these measures of central tendency coincide at the center of the distribution.\n",
    "\n",
    "It's important to note that while this relationship holds true for a perfect or idealized normal distribution, real-world data may exhibit deviations from perfect normality due to various factors. In such cases, the equality among the mean, median, and mode may not be exact but can still be relatively close, especially for datasets that approximate a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539257f",
   "metadata": {},
   "source": [
    "#Q13\n",
    "\n",
    "Covariance and correlation are both measures used in statistics to describe the relationship between two variables, but they serve slightly different purposes and have distinct properties:\n",
    "\n",
    "1. Covariance:\n",
    "   - Covariance measures the degree to which two variables change together. It indicates whether an increase in one variable corresponds to an increase or decrease in another variable.\n",
    "   - The formula for the sample covariance between two variables X and Y is:\n",
    "     Cov(X, Y) = Σ [(X_i - X̄) * (Y_i - Ȳ)] / (n - 1), where X_i and Y_i are individual data points, X̄ and Ȳ are the sample means of X and Y, and n is the number of data points.\n",
    "   - Covariance can be positive, negative, or zero:\n",
    "     - Positive covariance indicates that as one variable increases, the other tends to increase as well.\n",
    "     - Negative covariance indicates that as one variable increases, the other tends to decrease.\n",
    "     - Zero covariance indicates no linear relationship between the variables.\n",
    "   - However, the magnitude of covariance is not standardized and can be difficult to interpret because it depends on the units of the variables. Therefore, it's not a good measure for comparing the strength of relationships between different pairs of variables.\n",
    "\n",
    "2. Correlation:\n",
    "   - Correlation is a standardized measure that quantifies the strength and direction of the linear relationship between two variables. It provides a more interpretable and consistent measure of association than covariance.\n",
    "   - The most commonly used correlation coefficient is the Pearson correlation coefficient (often denoted as \"r\"), which ranges from -1 to 1:\n",
    "     - r = 1 indicates a perfect positive linear relationship.\n",
    "     - r = -1 indicates a perfect negative linear relationship.\n",
    "     - r = 0 indicates no linear relationship.\n",
    "   - The formula for the Pearson correlation coefficient is:\n",
    "     r = Σ [(X_i - X̄) * (Y_i - Ȳ)] / [√Σ(X_i - X̄)² * Σ(Y_i - Ȳ)²]\n",
    "   - Unlike covariance, correlation is unitless and always falls within the range of -1 to 1, making it easier to compare and interpret the strength and direction of relationships between variables.\n",
    "   - Correlation also helps identify both positive and negative linear relationships, as well as the strength of those relationships.\n",
    "\n",
    "In summary:\n",
    "\n",
    "- Covariance measures the degree of joint variability between two variables, but its magnitude depends on the units of the variables and doesn't provide a standardized measure of the strength of the relationship.\n",
    "\n",
    "- Correlation is a standardized measure that quantifies the strength and direction of the linear relationship between two variables, making it more interpretable and suitable for comparing relationships between different pairs of variables.\n",
    "\n",
    "Correlation is particularly useful for understanding and modeling relationships between variables, identifying patterns, and making predictions. It provides valuable insights into how changes in one variable relate to changes in another variable, allowing for more robust statistical analysis and decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727b6223",
   "metadata": {},
   "source": [
    "#Q14\n",
    "\n",
    "Outliers can significantly affect measures of central tendency (mean, median, mode) and measures of dispersion (range, variance, standard deviation) in a dataset. Their impact depends on the nature and magnitude of the outliers. Here's how outliers affect these measures, along with an example:\n",
    "\n",
    "1. Measures of Central Tendency:\n",
    "   - Mean: Outliers, especially extreme ones, can heavily influence the mean because it involves summing all data points and dividing by the number of data points. Outliers pull the mean toward their extreme values.\n",
    "   - Median: The median is less affected by outliers because it is not influenced by the specific values of outliers, only their position relative to the other data points.\n",
    "   - Mode: The mode may be unaffected by outliers, especially if they are far from the modal value. However, if an outlier coincides with the mode, it can change the mode.\n",
    "\n",
    "Example:\n",
    "   Let's consider a dataset of salaries for a company:\n",
    "   [40, 45, 50, 55, 60, 1000]\n",
    "\n",
    "   - Mean: The presence of the outlier (1000) significantly raises the mean, making it much larger than the typical salaries of the employees.\n",
    "   - Median: The median is less affected because it remains close to the central value (55) and doesn't get influenced by the outlier.\n",
    "   - Mode: The mode remains unaffected because it's still 55.\n",
    "\n",
    "2. Measures of Dispersion:\n",
    "   - Range: Outliers can widen the range considerably, especially if they are extreme values. The range is the difference between the maximum and minimum values in the dataset, so outliers directly impact this measure.\n",
    "   - Variance and Standard Deviation: Outliers can increase the variance and standard deviation since these measures consider the squared differences between data points and the mean. Outliers with large deviations from the mean have a substantial effect on these measures.\n",
    "\n",
    "Example:\n",
    "   Let's consider a dataset of test scores:\n",
    "   [78, 82, 85, 88, 95, 250]\n",
    "\n",
    "   - Range: The presence of the outlier (250) significantly widens the range from 78 to 250.\n",
    "   - Variance and Standard Deviation: The outlier's large deviation from the mean (114.67) increases both the variance and standard deviation compared to what they would be without the outlier.\n",
    "\n",
    "In summary, outliers can distort the interpretation of central tendency and dispersion measures. It's crucial to identify and handle outliers appropriately in data analysis to avoid biased conclusions and to ensure that these measures accurately represent the typical characteristics and variability of the dataset. Depending on the context, you may choose to remove outliers, transform the data, or use robust statistical methods that are less affected by outliers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
